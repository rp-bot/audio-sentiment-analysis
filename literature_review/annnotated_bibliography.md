# Annotated Bibliography

## [1. AST Audio Spectrogram Transformer](AST_Audio_spectrogram_transformer.pdf)

-   CNN-Attention hybrid model
-   overall this paper informs about the current state of audio deep learning

## [2. Automatic Music Emotion Classification](Automatic_music_emotion_classification.pdf)

-   uses a basic CNN
-   they carry out multiple experiments
-   architecture is of interest in this paper
-   Dataset is also quite interesting
-   The paper notes that reducing the sampling rate from the original 44.1 kHz to 16 kHz did not adversely affect the results while significantly improving processing time

## [3. PANNs](PANNs_Large-Scale_Pretrained_Audio_Neural_Networks.pdf)

-   Very Interesting take on CNNs
-   Dataset is of interest in this paper

## [4.Robust Speech Emotion Detection](A_Robust_Speech_Emotion_Detection_Mechanism_Using_Supervised_Deep_Learning_Paradigms.pdf)

-   The algorithms and optimizations are quite interesting in this.
-   Their method for getting a spectrogram is also very cool
-   they compare models to prove that their proposed model is better.
-   Dataset:
    -   [RAVDESS](https://zenodo.org/records/1188976#.XsAXemgzaUk)
    -   [TESS](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess)
    -   [SAVEE](https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee)

## My own Dataset Collection

-   [Movie Trailer Audio](https://www.kaggle.com/datasets/watipaso/trailermelspec)
-   [Horror Movie Scenes](https://www.kaggle.com/datasets/kindngng/horrormovie11)
-   [FreeSound Datasets](https://labs.freesound.org/datasets/)

## Finding random papers

-   [Deep Learning Audio using CNNs](https://arxiv.org/abs/2309.05855)
-   [Emotify Dataset](http://www2.projects.science.uu.nl/memotion/emotifydata/)
